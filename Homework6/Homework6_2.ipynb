{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMLkKWwCPt+gd6jL5XPDPjj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mburkey3/Intro_to_ML/blob/main/Homework6/Homework6_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqqQhAyO3WuR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download and normalize the input images\n",
        "from torchvision import datasets\n",
        "data_path = '../data-unversioned/p1ch7/'\n",
        "tensor_cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))\n",
        "tensor_cifar10_val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "metadata": {
        "id": "HDwV4ZTY3hje",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5c61117-e08b-4dba-daa9-9543fdcff24b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data-unversioned/p1ch7/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 85242907.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data-unversioned/p1ch7/cifar-10-python.tar.gz to ../data-unversioned/p1ch7/\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the actual model\n",
        "n_out = 10\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(3072, 512),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(512, n_out),\n",
        "    nn.LogSoftmax(dim=1)\n",
        ")"
      ],
      "metadata": {
        "id": "wwKUPWdCbCmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_classifer(epoch, opt, M, lossFn, trainData, div) :\n",
        "    for E in range(1, epoch + 1) :\n",
        "        for img, label in trainData :\n",
        "            trainOut = M(img.view(img.shape[0], -1))\n",
        "            trainLoss = lossFn(trainOut, label)\n",
        "\n",
        "            opt.zero_grad()\n",
        "            trainLoss.backward()\n",
        "            opt.step()\n",
        "\n",
        "        if E % div == 0:\n",
        "            print(f\"Epoch {E}, Training loss {trainLoss.item():.4f}\")\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "8B_AJqD0cX7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validation_test(M, valData) :\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad() :\n",
        "        for img, label in valData :\n",
        "            batchSize = img.shape[0]\n",
        "            out = M(img.view(batchSize, -1))\n",
        "            _, predict = torch.max(out, dim=1)\n",
        "            total += label.shape[0]\n",
        "            correct += int((predict == label).sum())\n",
        "\n",
        "    print(\"Accuracy: \", correct / total)\n",
        "    return"
      ],
      "metadata": {
        "id": "viYY8mCHiuh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.001)\n",
        "\n",
        "trainLoader = torch.utils.data.DataLoader(tensor_cifar10, batch_size=64, shuffle=True) # This should speed up the process with mini batches\n",
        "\n",
        "training_classifer(\n",
        "    epoch = 10,\n",
        "    opt = optimizer,\n",
        "    M = model,\n",
        "    lossFn = nn.NLLLoss(),\n",
        "    trainData = trainLoader,\n",
        "    div = 1\n",
        ")"
      ],
      "metadata": {
        "id": "dezL58SBph9U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "202ab002-d8bd-4eeb-fc8d-a68f22a66bb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 2.1732\n",
            "Epoch 2, Training loss 1.8272\n",
            "Epoch 3, Training loss 1.9203\n",
            "Epoch 4, Training loss 2.0380\n",
            "Epoch 5, Training loss 1.5556\n",
            "Epoch 6, Training loss 1.8492\n",
            "Epoch 7, Training loss 1.6213\n",
            "Epoch 8, Training loss 1.6566\n",
            "Epoch 9, Training loss 1.8129\n",
            "Epoch 10, Training loss 1.6937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validating the model\n",
        "valLoader = torch.utils.data.DataLoader(tensor_cifar10_val, batch_size=64, shuffle=True) # This will seperate into mini batches to speed up the process\n",
        "\n",
        "validation_test(\n",
        "    M = model,\n",
        "    valData = valLoader\n",
        ")"
      ],
      "metadata": {
        "id": "15-VESBJqM7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44bce144-8ac9-4b8e-e386-32c30e01fc42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.4135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## PART B\n",
        "# Rebuild model with extra layers\n",
        "modelB = nn.Sequential(\n",
        "    nn.Linear(3072, 1536),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(1536, 768),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(768, 384),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(384, n_out),\n",
        "    nn.LogSoftmax(dim=1)\n",
        ")"
      ],
      "metadata": {
        "id": "SKoavW8lbsIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "optimizer = optim.SGD(modelB.parameters(), lr = 0.001)\n",
        "\n",
        "training_classifer(\n",
        "    epoch = 300,\n",
        "    opt = optimizer,\n",
        "    M = modelB,\n",
        "    lossFn = nn.NLLLoss(),\n",
        "    trainData = trainLoader,\n",
        "    div = 50\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaNNStdidx0c",
        "outputId": "8398ab5f-15d1-4901-ed47-b069b9f3d0e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50, Training loss 1.7690\n",
            "Epoch 100, Training loss 1.1511\n",
            "Epoch 150, Training loss 0.4502\n",
            "Epoch 200, Training loss 0.1442\n",
            "Epoch 250, Training loss 0.0329\n",
            "Epoch 300, Training loss 0.0090\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validating the larger model\n",
        "validation_test(\n",
        "    M = modelB,\n",
        "    valData = valLoader\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IdcRINuBfw1L",
        "outputId": "2e97d503-d32c-4c3f-9c77-c558dc20bd3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.4632\n"
          ]
        }
      ]
    }
  ]
}